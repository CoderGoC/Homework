{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "first_five_rows = df.head()\n",
    "print(first_five_rows)\n",
    "assert first_five_rows.shape[0] == 5, f\"Expected 5 rows, but got {first_five_rows.shape[0]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Calculate the mean age of passengers\n",
    "mean_age =  df['Age'].mean() # Calculate mean age\n",
    "print(mean_age)\n",
    "# Assert\n",
    "expected_mean_age = df['Age'].mean()\n",
    "assert np.isclose(mean_age, expected_mean_age), f\"Expected {expected_mean_age}, but got {mean_age}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 3: Find the number of missing values in the 'Cabin' column\n",
    "missing_cabin = df['Cabin'].isnull().sum()  # Find number of missing values\n",
    "# Assert\n",
    "print(missing_cabin)\n",
    "expected_missing_cabin = df['Cabin'].isnull().sum()\n",
    "assert missing_cabin == expected_missing_cabin, f\"Expected {expected_missing_cabin}, but got {missing_cabin}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "..           ...       ...     ...   \n",
      "880          881         1       2   \n",
      "882          883         0       3   \n",
      "885          886         0       3   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "8        2            347742  11.1333   NaN        S  \n",
      "9        0            237736  30.0708   NaN        C  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "880      1            230433  26.0000   NaN        S  \n",
      "882      0              7552  10.5167   NaN        S  \n",
      "885      5            382652  29.1250   NaN        Q  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "\n",
      "[314 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 4: Filter the DataFrame to include only female passengers\n",
    "female_df = df[df['Sex'] == 'female']  # Filter DataFrame\n",
    "print(female_df)\n",
    "# Assert\n",
    "assert female_df['Sex'].unique() == ['female'], \"DataFrame contains non-female passengers\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.38383838383838\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 5: Calculate the survival rate (percentage) of passengers\n",
    "survival_rate = df[\"Survived\"].mean() * 100  # Calculate survival rate\n",
    "print(survival_rate)\n",
    "# Assert\n",
    "expected_survival_rate = (df['Survived'].mean()) * 100\n",
    "assert np.isclose(survival_rate, expected_survival_rate), f\"Expected {expected_survival_rate}, but got {survival_rate}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    0\n",
      "888    3\n",
      "889    0\n",
      "890    0\n",
      "Length: 891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 6: Create a new column 'FamilySize' as the sum of 'SibSp' and 'Parch'\n",
    "df['FamilySize'] = df[\"SibSp\"] + df[\"Parch\"]  # Create new column\n",
    "# Assert\n",
    "expected_family_size = df['SibSp'] + df['Parch']\n",
    "print(expected_family_size )\n",
    "assert df['FamilySize'].equals(expected_family_size), \"Column 'FamilySize' not created correctly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 7: Find the most common embarkation point (i.e., the value that appears most frequently in 'Embarked')\n",
    "most_common_embarkation = df[\"Embarked\"].mode()[0]  # Find most common embarkation point\n",
    "# Assert\n",
    "print(most_common_embarkation)\n",
    "expected_common_embarkation = df['Embarked'].mode()[0]\n",
    "assert most_common_embarkation == expected_common_embarkation, f\"Expected {expected_common_embarkation}, but got {most_common_embarkation}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84.1546875, 20.662183152173913, 13.675550101832993]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 8: Calculate the mean fare for each class (Pclass)\n",
    "mean_fare_by_class = df.groupby(\"Pclass\")['Fare'].mean().to_list()  # Calculate mean fare by class\n",
    "# Assert\n",
    "print(mean_fare_by_class)\n",
    "expected_mean_fare_by_class = df.groupby('Pclass')['Fare'].mean().to_list()\n",
    "assert mean_fare_by_class == expected_mean_fare_by_class, f\"Expected {expected_mean_fare_by_class}, but got {mean_fare_by_class}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "803          804         1       3           Thomas, Master. Assad Alexander   \n",
      "755          756         1       2                 Hamalainen, Master. Viljo   \n",
      "469          470         1       3             Baclini, Miss. Helene Barbara   \n",
      "644          645         1       3                    Baclini, Miss. Eugenie   \n",
      "78            79         1       2             Caldwell, Master. Alden Gates   \n",
      "..           ...       ...     ...                                       ...   \n",
      "859          860         0       3                          Razi, Mr. Raihed   \n",
      "863          864         0       3         Sage, Miss. Dorothy Edith \"Dolly\"   \n",
      "868          869         0       3               van Melkebeke, Mr. Philemon   \n",
      "878          879         0       3                        Laleff, Mr. Kristo   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \\\n",
      "803    male  0.42      0      1        2625   8.5167   NaN        C   \n",
      "755    male  0.67      1      1      250649  14.5000   NaN        S   \n",
      "469  female  0.75      2      1        2666  19.2583   NaN        C   \n",
      "644  female  0.75      2      1        2666  19.2583   NaN        C   \n",
      "78     male  0.83      0      2      248738  29.0000   NaN        S   \n",
      "..      ...   ...    ...    ...         ...      ...   ...      ...   \n",
      "859    male   NaN      0      0        2629   7.2292   NaN        C   \n",
      "863  female   NaN      8      2    CA. 2343  69.5500   NaN        S   \n",
      "868    male   NaN      0      0      345777   9.5000   NaN        S   \n",
      "878    male   NaN      0      0      349217   7.8958   NaN        S   \n",
      "888  female   NaN      1      2  W./C. 6607  23.4500   NaN        S   \n",
      "\n",
      "     FamilySize  \n",
      "803           1  \n",
      "755           2  \n",
      "469           3  \n",
      "644           3  \n",
      "78            2  \n",
      "..          ...  \n",
      "859           0  \n",
      "863          10  \n",
      "868           0  \n",
      "878           0  \n",
      "888           3  \n",
      "\n",
      "[891 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 9: Sort the DataFrame by 'Age' in ascending order\n",
    "sorted_by_age_df = df.sort_values(by='Age')  # Sort DataFrame\n",
    "# Assert\n",
    "print(sorted_by_age_df)\n",
    "expected_sorted_names_by_age = df.sort_values(by='Age')['Name'].tolist()\n",
    "assert sorted_by_age_df['Name'].tolist() == expected_sorted_names_by_age, \"DataFrame not sorted correctly by age\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  PassengerId  Survived  Pclass  \\\n",
      "0        0            1         0       3   \n",
      "1        1            2         1       1   \n",
      "2        2            3         1       3   \n",
      "3        3            4         1       1   \n",
      "4        4            5         0       3   \n",
      "..     ...          ...       ...     ...   \n",
      "886    886          887         0       2   \n",
      "887    887          888         1       1   \n",
      "888    888          889         0       3   \n",
      "889    889          890         1       1   \n",
      "890    890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  FamilySize  \n",
      "0        0         A/5 21171   7.2500   NaN        S           1  \n",
      "1        0          PC 17599  71.2833   C85        C           1  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S           0  \n",
      "3        0            113803  53.1000  C123        S           1  \n",
      "4        0            373450   8.0500   NaN        S           0  \n",
      "..     ...               ...      ...   ...      ...         ...  \n",
      "886      0            211536  13.0000   NaN        S           0  \n",
      "887      0            112053  30.0000   B42        S           0  \n",
      "888      2        W./C. 6607  23.4500   NaN        S           3  \n",
      "889      0            111369  30.0000  C148        C           0  \n",
      "890      0            370376   7.7500   NaN        Q           0  \n",
      "\n",
      "[891 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 10: Reset the index of the sorted DataFrame\n",
    "reset_sorted_by_age_df = df.reset_index()  # Reset index\n",
    "# Assert\n",
    "print(reset_sorted_by_age_df)\n",
    "assert reset_sorted_by_age_df.index.tolist() == list(range(df.shape[0])), f\"Index not reset correctly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exercise 11: Find the unique values in the 'Pclass' column\n",
    "unique_pclass_values = df[\"Pclass\"].unique()  # Find unique values\n",
    "# Assert\n",
    "print(unique_pclass_values)\n",
    "expected_unique_pclass_values = df['Pclass'].unique()\n",
    "assert np.array_equal(unique_pclass_values, expected_unique_pclass_values), f\"Expected {expected_unique_pclass_values}, but got {unique_pclass_values}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "1              2         1       1   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "6              7         0       1   \n",
      "11            12         1       1   \n",
      "..           ...       ...     ...   \n",
      "873          874         0       3   \n",
      "879          880         1       1   \n",
      "881          882         0       3   \n",
      "885          886         0       3   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
      "881                                 Markun, Mr. Johann    male  33.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch    Ticket     Fare Cabin Embarked  FamilySize  \n",
      "1        0  PC 17599  71.2833   C85        C           1  \n",
      "3        0    113803  53.1000  C123        S           1  \n",
      "4        0    373450   8.0500   NaN        S           0  \n",
      "6        0     17463  51.8625   E46        S           0  \n",
      "11       0    113783  26.5500  C103        S           0  \n",
      "..     ...       ...      ...   ...      ...         ...  \n",
      "873      0    345765   9.0000   NaN        S           0  \n",
      "879      1     11767  83.1583   C50        C           1  \n",
      "881      0    349257   7.8958   NaN        S           0  \n",
      "885      5    382652  29.1250   NaN        Q           5  \n",
      "890      0    370376   7.7500   NaN        Q           0  \n",
      "\n",
      "[305 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 12: Filter passengers older than 30\n",
    "older_than_30_df = df[df[\"Age\"]>30]  # Filter passengers older than 30\n",
    "# Assert\n",
    "print(older_than_30_df)\n",
    "assert older_than_30_df['Age'].min() > 30, \"DataFrame contains passengers 30 or younger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.6296296296296297, 2: 0.47282608695652173, 3: 0.24236252545824846}\n"
     ]
    }
   ],
   "source": [
    "# Exercise 13: Create a pivot table with 'Pclass' as rows and 'Survived' as values, calculating the mean survival rate per class\n",
    "pivot_table_survival = df.pivot_table(values=\"Survived\", index=\"Pclass\", aggfunc=\"mean\").to_dict()[\"Survived\"] \n",
    "# Create pivot table\n",
    "print(pivot_table_survival)\n",
    "# Assert\n",
    "expected_pivot_table_survival = df.pivot_table(values='Survived', index='Pclass', aggfunc='mean').to_dict()['Survived']\n",
    "assert pivot_table_survival == expected_pivot_table_survival, f\"Expected {expected_pivot_table_survival}, but got {pivot_table_survival}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.6934285971809\n"
     ]
    }
   ],
   "source": [
    "# Exercise 14: Calculate the standard deviation of the 'Fare' column\n",
    "fare_std = df[\"Fare\"].std()  # Calculate standard deviation\n",
    "# Assert\n",
    "print(fare_std)\n",
    "expected_fare_std = df['Fare'].std()\n",
    "assert np.isclose(fare_std, expected_fare_std), f\"Expected {expected_fare_std}, but got {fare_std}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass            Name   Sex  Age  SibSp  Parch  \\\n",
      "0          892         0       3  Test Passenger  male   25      0      0   \n",
      "\n",
      "  Ticket  Fare Cabin Embarked  \n",
      "0   0000  7.25   E50        S  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 15: Add a row for a new passenger with the following details: \n",
    "# Name: 'Test Passenger', Pclass: 3, Age: 25, SibSp: 0, Parch: 0, Ticket: '0000', Fare: 7.25, Cabin: 'E50', Embarked: 'S'\n",
    "new_passenger = pd.DataFrame([{\n",
    "    'PassengerId': df['PassengerId'].max() + 1,\n",
    "    'Survived': 0,\n",
    "    'Pclass': 3,\n",
    "    'Name': 'Test Passenger',\n",
    "    'Sex': 'male',\n",
    "    'Age': 25,\n",
    "    'SibSp': 0,\n",
    "    'Parch': 0,\n",
    "    'Ticket': '0000',\n",
    "    'Fare': 7.25,\n",
    "    'Cabin': 'E50',\n",
    "    'Embarked': 'S'\n",
    "}])\n",
    "df = pd.concat([df, new_passenger], ignore_index=True)  # Add new passenger\n",
    "# Assert\n",
    "print(new_passenger)\n",
    "assert df.iloc[-1]['Name'] == 'Test Passenger', \"New passenger not added correctly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.corr of      PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "891          892         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "891                                     Test Passenger    male  25.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  FamilySize  \n",
      "0        0         A/5 21171   7.2500   NaN        S         1.0  \n",
      "1        0          PC 17599  71.2833   C85        C         1.0  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S         0.0  \n",
      "3        0            113803  53.1000  C123        S         1.0  \n",
      "4        0            373450   8.0500   NaN        S         0.0  \n",
      "..     ...               ...      ...   ...      ...         ...  \n",
      "887      0            112053  30.0000   B42        S         0.0  \n",
      "888      2        W./C. 6607  23.4500   NaN        S         3.0  \n",
      "889      0            111369  30.0000  C148        C         0.0  \n",
      "890      0            370376   7.7500   NaN        Q         0.0  \n",
      "891      0              0000   7.2500   E50        S         NaN  \n",
      "\n",
      "[892 rows x 13 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Exercise 16: Calculate the correlation matrix of the DataFrame\n",
    "correlation_matrix = df.corr  # Calculate correlation matrix\n",
    "# Assert\n",
    "print(correlation_matrix)\n",
    "assert correlation_matrix is not None, \"Correlation matrix is None\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "27            28         0       1   \n",
      "31            32         1       1   \n",
      "88            89         1       1   \n",
      "118          119         0       1   \n",
      "195          196         1       1   \n",
      "215          216         1       1   \n",
      "258          259         1       1   \n",
      "268          269         1       1   \n",
      "269          270         1       1   \n",
      "297          298         0       1   \n",
      "299          300         1       1   \n",
      "305          306         1       1   \n",
      "306          307         1       1   \n",
      "307          308         1       1   \n",
      "311          312         1       1   \n",
      "318          319         1       1   \n",
      "319          320         1       1   \n",
      "325          326         1       1   \n",
      "332          333         0       1   \n",
      "334          335         1       1   \n",
      "337          338         1       1   \n",
      "341          342         1       1   \n",
      "373          374         0       1   \n",
      "377          378         0       1   \n",
      "380          381         1       1   \n",
      "390          391         1       1   \n",
      "393          394         1       1   \n",
      "435          436         1       1   \n",
      "438          439         0       1   \n",
      "498          499         0       1   \n",
      "505          506         0       1   \n",
      "527          528         0       1   \n",
      "537          538         1       1   \n",
      "544          545         0       1   \n",
      "550          551         1       1   \n",
      "557          558         0       1   \n",
      "581          582         1       1   \n",
      "609          610         1       1   \n",
      "659          660         0       1   \n",
      "660          661         1       1   \n",
      "679          680         1       1   \n",
      "689          690         1       1   \n",
      "698          699         0       1   \n",
      "700          701         1       1   \n",
      "708          709         1       1   \n",
      "716          717         1       1   \n",
      "730          731         1       1   \n",
      "737          738         1       1   \n",
      "742          743         1       1   \n",
      "763          764         1       1   \n",
      "779          780         1       1   \n",
      "802          803         1       1   \n",
      "856          857         1       1   \n",
      "\n",
      "                                                  Name     Sex    Age  SibSp  \\\n",
      "27                      Fortune, Mr. Charles Alexander    male  19.00      3   \n",
      "31      Spencer, Mrs. William Augustus (Marie Eugenie)  female    NaN      1   \n",
      "88                          Fortune, Miss. Mabel Helen  female  23.00      3   \n",
      "118                           Baxter, Mr. Quigg Edmond    male  24.00      0   \n",
      "195                               Lurette, Miss. Elise  female  58.00      0   \n",
      "215                            Newell, Miss. Madeleine  female  31.00      1   \n",
      "258                                   Ward, Miss. Anna  female  35.00      0   \n",
      "268      Graham, Mrs. William Thompson (Edith Junkins)  female  58.00      0   \n",
      "269                             Bissette, Miss. Amelia  female  35.00      0   \n",
      "297                       Allison, Miss. Helen Loraine  female   2.00      1   \n",
      "299    Baxter, Mrs. James (Helene DeLaudeniere Chaput)  female  50.00      0   \n",
      "305                     Allison, Master. Hudson Trevor    male   0.92      1   \n",
      "306                            Fleming, Miss. Margaret  female    NaN      0   \n",
      "307  Penasco y Castellana, Mrs. Victor de Satode (M...  female  17.00      1   \n",
      "311                         Ryerson, Miss. Emily Borie  female  18.00      2   \n",
      "318                           Wick, Miss. Mary Natalie  female  31.00      0   \n",
      "319  Spedden, Mrs. Frederic Oakley (Margaretta Corn...  female  40.00      1   \n",
      "325                           Young, Miss. Marie Grice  female  36.00      0   \n",
      "332                          Graham, Mr. George Edward    male  38.00      0   \n",
      "334  Frauenthal, Mrs. Henry William (Clara Heinshei...  female    NaN      1   \n",
      "337                    Burns, Miss. Elizabeth Margaret  female  41.00      0   \n",
      "341                     Fortune, Miss. Alice Elizabeth  female  24.00      3   \n",
      "373                                Ringhini, Mr. Sante    male  22.00      0   \n",
      "377                          Widener, Mr. Harry Elkins    male  27.00      0   \n",
      "380                              Bidois, Miss. Rosalie  female  42.00      0   \n",
      "390                         Carter, Mr. William Ernest    male  36.00      1   \n",
      "393                             Newell, Miss. Marjorie  female  23.00      1   \n",
      "435                          Carter, Miss. Lucile Polk  female  14.00      1   \n",
      "438                                  Fortune, Mr. Mark    male  64.00      1   \n",
      "498    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.00      1   \n",
      "505         Penasco y Castellana, Mr. Victor de Satode    male  18.00      1   \n",
      "527                                 Farthing, Mr. John    male    NaN      0   \n",
      "537                                LeRoy, Miss. Bertha  female  30.00      0   \n",
      "544                         Douglas, Mr. Walter Donald    male  50.00      1   \n",
      "550                        Thayer, Mr. John Borland Jr    male  17.00      0   \n",
      "557                                Robbins, Mr. Victor    male    NaN      0   \n",
      "581  Thayer, Mrs. John Borland (Marian Longstreth M...  female  39.00      1   \n",
      "609                          Shutes, Miss. Elizabeth W  female  40.00      0   \n",
      "659                         Newell, Mr. Arthur Webster    male  58.00      0   \n",
      "660                      Frauenthal, Dr. Henry William    male  50.00      2   \n",
      "679                 Cardeza, Mr. Thomas Drake Martinez    male  36.00      0   \n",
      "689                  Madill, Miss. Georgette Alexandra  female  15.00      0   \n",
      "698                           Thayer, Mr. John Borland    male  49.00      1   \n",
      "700  Astor, Mrs. John Jacob (Madeleine Talmadge Force)  female  18.00      1   \n",
      "708                               Cleaver, Miss. Alice  female  22.00      0   \n",
      "716                      Endres, Miss. Caroline Louise  female  38.00      0   \n",
      "730                      Allen, Miss. Elisabeth Walton  female  29.00      0   \n",
      "737                             Lesurer, Mr. Gustave J    male  35.00      0   \n",
      "742              Ryerson, Miss. Susan Parker \"Suzette\"  female  21.00      2   \n",
      "763          Carter, Mrs. William Ernest (Lucile Polk)  female  36.00      1   \n",
      "779  Robert, Mrs. Edward Scott (Elisabeth Walton Mc...  female  43.00      0   \n",
      "802                Carter, Master. William Thornton II    male  11.00      1   \n",
      "856         Wick, Mrs. George Dennick (Mary Hitchcock)  female  45.00      1   \n",
      "\n",
      "     Parch    Ticket      Fare            Cabin Embarked  FamilySize  \n",
      "27       2     19950  263.0000      C23 C25 C27        S         5.0  \n",
      "31       0  PC 17569  146.5208              B78        C         1.0  \n",
      "88       2     19950  263.0000      C23 C25 C27        S         5.0  \n",
      "118      1  PC 17558  247.5208          B58 B60        C         1.0  \n",
      "195      0  PC 17569  146.5208              B80        C         0.0  \n",
      "215      0     35273  113.2750              D36        C         1.0  \n",
      "258      0  PC 17755  512.3292              NaN        C         0.0  \n",
      "268      1  PC 17582  153.4625             C125        S         1.0  \n",
      "269      0  PC 17760  135.6333              C99        S         0.0  \n",
      "297      2    113781  151.5500          C22 C26        S         3.0  \n",
      "299      1  PC 17558  247.5208          B58 B60        C         1.0  \n",
      "305      2    113781  151.5500          C22 C26        S         3.0  \n",
      "306      0     17421  110.8833              NaN        C         0.0  \n",
      "307      0  PC 17758  108.9000              C65        C         1.0  \n",
      "311      2  PC 17608  262.3750  B57 B59 B63 B66        C         4.0  \n",
      "318      2     36928  164.8667               C7        S         2.0  \n",
      "319      1     16966  134.5000              E34        C         2.0  \n",
      "325      0  PC 17760  135.6333              C32        C         0.0  \n",
      "332      1  PC 17582  153.4625              C91        S         1.0  \n",
      "334      0  PC 17611  133.6500              NaN        S         1.0  \n",
      "337      0     16966  134.5000              E40        C         0.0  \n",
      "341      2     19950  263.0000      C23 C25 C27        S         5.0  \n",
      "373      0  PC 17760  135.6333              NaN        C         0.0  \n",
      "377      2    113503  211.5000              C82        C         2.0  \n",
      "380      0  PC 17757  227.5250              NaN        C         0.0  \n",
      "390      2    113760  120.0000          B96 B98        S         3.0  \n",
      "393      0     35273  113.2750              D36        C         1.0  \n",
      "435      2    113760  120.0000          B96 B98        S         3.0  \n",
      "438      4     19950  263.0000      C23 C25 C27        S         5.0  \n",
      "498      2    113781  151.5500          C22 C26        S         3.0  \n",
      "505      0  PC 17758  108.9000              C65        C         1.0  \n",
      "527      0  PC 17483  221.7792              C95        S         0.0  \n",
      "537      0  PC 17761  106.4250              NaN        C         0.0  \n",
      "544      0  PC 17761  106.4250              C86        C         1.0  \n",
      "550      2     17421  110.8833              C70        C         2.0  \n",
      "557      0  PC 17757  227.5250              NaN        C         0.0  \n",
      "581      1     17421  110.8833              C68        C         2.0  \n",
      "609      0  PC 17582  153.4625             C125        S         0.0  \n",
      "659      2     35273  113.2750              D48        C         2.0  \n",
      "660      0  PC 17611  133.6500              NaN        S         2.0  \n",
      "679      1  PC 17755  512.3292      B51 B53 B55        C         1.0  \n",
      "689      1     24160  211.3375               B5        S         1.0  \n",
      "698      1     17421  110.8833              C68        C         2.0  \n",
      "700      0  PC 17757  227.5250          C62 C64        C         1.0  \n",
      "708      0    113781  151.5500              NaN        S         0.0  \n",
      "716      0  PC 17757  227.5250              C45        C         0.0  \n",
      "730      0     24160  211.3375               B5        S         0.0  \n",
      "737      0  PC 17755  512.3292             B101        C         0.0  \n",
      "742      2  PC 17608  262.3750  B57 B59 B63 B66        C         4.0  \n",
      "763      2    113760  120.0000          B96 B98        S         3.0  \n",
      "779      1     24160  211.3375               B3        S         1.0  \n",
      "802      2    113760  120.0000          B96 B98        S         3.0  \n",
      "856      1     36928  164.8667              NaN        S         2.0  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 17: Filter the DataFrame for passengers who paid a fare greater than 100\n",
    "high_fare_df = df[df[\"Fare\"]>100] # Filter high fare passengers\n",
    "# Assert\n",
    "print(high_fare_df)\n",
    "assert high_fare_df['Fare'].min() > 100, \"DataFrame contains passengers who paid 100 or less\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 30.81476923076923, 'Q': 28.089285714285715, 'S': 29.43738738738739}\n"
     ]
    }
   ],
   "source": [
    "# Exercise 18: Calculate the average age of passengers for each embarkation point\n",
    "average_age_by_embarkation = df.groupby(\"Embarked\")[\"Age\"].mean().to_dict()  # Calculate average age by embarkation\n",
    "# Assert\n",
    "print(average_age_by_embarkation)\n",
    "expected_average_age_by_embarkation = df.groupby('Embarked')['Age'].mean().to_dict()\n",
    "assert average_age_by_embarkation == expected_average_age_by_embarkation, f\"Expected {expected_average_age_by_embarkation}, but got {average_age_by_embarkation}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 492, 1: 216, 2: 184}\n"
     ]
    }
   ],
   "source": [
    "# Exercise 19: Find the number of passengers in each class\n",
    "passenger_count_by_class = df[\"Pclass\"].value_counts().to_dict()  # Find number of passengers in each class\n",
    "# Assert\n",
    "print(passenger_count_by_class)\n",
    "expected_passenger_count_by_class = df['Pclass'].value_counts().to_dict()\n",
    "assert passenger_count_by_class == expected_passenger_count_by_class, f\"Expected {expected_passenger_count_by_class}, but got {passenger_count_by_class}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Child', 'Child', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Child', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Senior', 'Senior', 'Adult', 'Senior', 'Senior', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Senior', 'Senior', 'Senior', 'Senior', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Child', 'Child', 'Adult', 'Adult', 'Adult', 'Child', 'Senior', 'Senior', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Child', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Child', 'Child', 'Senior', 'Adult', 'Senior', 'Adult', 'Senior', 'Child', 'Child', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Child', 'Child', 'Child', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Senior', 'Child', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Senior', 'Adult', 'Senior', 'Senior', 'Adult', 'Senior', 'Senior', 'Child', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Senior', 'Adult', 'Adult', 'Child', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Senior', 'Senior', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Child', 'Child', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Senior', 'Child', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Child', 'Senior', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Senior', 'Child', 'Senior', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Child', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Child', 'Adult', 'Child', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Child', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Child', 'Child', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Child', 'Senior', 'Adult', 'Child', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Child', 'Adult', 'Senior', 'Child', 'Senior', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Senior', 'Senior', 'Child', 'Senior', 'Senior', 'Child', 'Child', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Senior', 'Adult', 'Child', 'Adult', 'Adult', 'Child', 'Adult', 'Senior', 'Adult', 'Adult', 'Senior', 'Child', 'Senior', 'Child', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Child', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Child', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Adult', 'Senior', 'Adult', 'Adult', 'Adult']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 20: Create a new column 'AgeGroup' categorizing passengers as 'Child' (<18), 'Adult' (18-60), 'Senior' (>60)\n",
    "def categorize_age(age):\n",
    "    if age < 18:\n",
    "        return 'Child'\n",
    "    elif age <= 60:\n",
    "        return 'Adult'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "df['AgeGroup'] = df[\"Age\"].apply(categorize_age).tolist()  # Create new column\n",
    "# Assert\n",
    "expected_age_groups = df['Age'].apply(categorize_age).tolist()\n",
    "print(expected_age_groups)\n",
    "assert df['AgeGroup'].tolist() == expected_age_groups, \"Column 'AgeGroup' not created correctly\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
